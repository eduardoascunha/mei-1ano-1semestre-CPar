https://godbolt.org/

Vector processing √© uma t√©cnica de computa√ß√£o que permite realizar opera√ß√µes em m√∫ltiplos dados simultaneamente usando um √∫nico comando. Ao inv√©s de processar um √∫nico dado por vez (como na maioria dos processadores tradicionais), o processador executa a mesma opera√ß√£o em um conjunto de dados (ou vetor).

Como funciona:
Em vez de processar uma opera√ß√£o para cada elemento de um vetor de forma sequencial (elemento a elemento), o processador executa uma instru√ß√£o que pode operar em v√°rios elementos ao mesmo tempo. Por exemplo, se quisermos somar dois vetores 
A e ùêµ de tamanho 4, um processador tradicional faria quatro opera√ß√µes de soma (uma para cada par de elementos). Com o vector processing, o processador pode realizar todas as somas simultaneamente.


1-
a) salto de 8 para salto de 64, foi desdobrado para um salto de 8 valores de cada vez

b)  
A vers√£o com unrolling (unroll) deve apresentar melhor desempenho em rela√ß√£o √† vers√£o base.

Redu√ß√£o da Sobrecarga de Controle de Loop: Ao usar loop unrolling, o n√∫mero de vezes que o loop precisa ser controlado (i.e., incrementar o contador, verificar a condi√ß√£o de t√©rmino) √© reduzido. Em vez de fazer uma opera√ß√£o de controle por itera√ß√£o, o processador executa v√°rias opera√ß√µes antes de verificar a condi√ß√£o de t√©rmino novamente. Isso diminui a sobrecarga associada ao controle do loop.

Melhor Utiliza√ß√£o do Pipeline: Os processadores modernos possuem pipelines que permitem a execu√ß√£o de v√°rias instru√ß√µes simultaneamente. No entanto, interrup√ß√µes frequentes causadas pelo controle de loop podem atrapalhar o fluxo cont√≠nuo de instru√ß√µes no pipeline. O loop unrolling aumenta a quantidade de trabalho entre as verifica√ß√µes de controle, permitindo que o pipeline seja mais bem utilizado, o que resulta em menos "stalls" (paradas) e maior efici√™ncia.

Resultado esperado:
A vers√£o unroll provavelmente ter√° valores menores de CPI (ciclos por instru√ß√£o), ou seja, mais instru√ß√µes executadas por ciclo, e semelhantes L1 cache misses, comparado √† vers√£o base. Unroll + instru√ß√µes. 

2-
a) 
n√£o esta a usar a transposta
dependecia da multiplica√ß√£o entre A e B antes da soma na matriz C

Duas raz√µes pelas quais o c√≥digo base n√£o pode ser vetorizado:
Padr√µes de acesso n√£o sequenciais √† mem√≥ria:

A multiplica√ß√£o de matrizes envolve tr√™s loops aninhados que acessam elementos das matrizes de forma diferente. A matriz 
A[i][k] √© acessada sequencialmente em cada linha (bom para vetorizar), mas a matriz B[k][j] √© acessada por colunas (n√£o sequencialmente na mem√≥ria, em geral). Isso resulta em acessos dispersos na mem√≥ria (n√£o lineares) para a matriz B, o que dificulta a vetoriza√ß√£o, pois a efici√™ncia da vetoriza√ß√£o depende de acessos cont√≠guos a dados.

Depend√™ncia de dados:
No c√≥digo base, h√° uma acumula√ß√£o de resultados na matriz C[i][j], ou seja, o valor de  C[i][j] √© atualizado a cada itera√ß√£o do loop interno. Esse tipo de depend√™ncia de dados (onde o valor de C[i][j] depende dos valores anteriores computados nas itera√ß√µes anteriores) impede que m√∫ltiplas itera√ß√µes sejam executadas simultaneamente de forma vetorizada, porque o compilador n√£o pode reorganizar a ordem de c√°lculo de forma segura sem quebrar a l√≥gica do algoritmo.
Para vetorizar eficientemente, o compilador precisa de opera√ß√µes independentes entre itera√ß√µes, algo que n√£o acontece aqui devido a essa depend√™ncia de dados.

b) sem transposta, alterar ordem dos loops (i,k,j)
Por que essa ordem permite vetoriza√ß√£o?
Acesso cont√≠guo √† matriz B:
No c√≥digo original (ordem "ijk"), a matriz B √© acessada por colunas (B[k][j]), o que n√£o resulta em acessos cont√≠guos na mem√≥ria, dificultando a vetoriza√ß√£o.
Ao mudar para a ordem "ikj", o loop mais interno passa a iterar sobre j, que percorre as colunas de C e de B[k][j], garantindo um acesso cont√≠guo √† mem√≥ria para B.

Acesso eficiente √† matriz C:
Na nova ordem, cada elemento de C[i][j] √© atualizado de maneira sequencial em colunas, o que pode ser vetorizado facilmente, j√° que os valores de C[i][j] podem ser acumulados em vetores de 128 ou 256 bits, dependendo do conjunto de instru√ß√µes vetoriais (como SSE ou AVX).

Acesso cont√≠guo √† matriz A:
A matriz A[i][k] continua sendo acessada por linhas, o que j√° √© cont√≠guo na mem√≥ria na maioria das implementa√ß√µes de matrizes, o que √© favor√°vel para a vetoriza√ß√£o.

3-
a)
√© solicitado o c√°lculo da performace de pico em uma arquitetura com instru√ß√µes vetoriais de 256 bits, usando vetores de 128 bits (double precision) e com uma m√°quina funcionando a 2,5 GHz.

Passos para determinar a performance de pico:
Definir a performance de pico em opera√ß√µes de ponto flutuante (FLOP/s):
A m√°quina tem um desempenho de pico de 256 bits por ciclo, o que significa que a cada ciclo de clock, ela pode realizar opera√ß√µes com dois valores de ponto flutuante de 64 bits simultaneamente (vetores de double precision).
C√°lculo do n√∫mero de FLOP/s:
Sabemos que cada ciclo da m√°quina permite realizar 2 opera√ß√µes de ponto flutuante de precis√£o dupla (64 bits).
O clock da m√°quina √© de 2,5 GHz, o que significa que a m√°quina executa 2,5 bilh√µes de ciclos por segundo.
Para calcular o FLOP/s (opera√ß√µes de ponto flutuante por segundo), multiplicamos o n√∫mero de opera√ß√µes por ciclo pelo n√∫mero de ciclos por segundo:
FLOP/s=2FLOP/ciclo√ó2.5√ó10^9ciclos/segundo
FLOP/s=5√ó10^9FLOP/s
Assim, a performance de pico da m√°quina √© 5 GFLOP/s (5 bilh√µes de opera√ß√µes de ponto flutuante por segundo).

Tempo necess√°rio para a multiplica√ß√£o de matrizes 1024x1024:
Para calcular o tempo necess√°rio para realizar uma multiplica√ß√£o de matrizes de 1024x1024, precisamos calcular quantas opera√ß√µes de ponto flutuante s√£o necess√°rias.
A multiplica√ß√£o de duas matrizes A (N x N) e B (N x N) resulta em uma matriz C (N x N). Cada elemento de C √© obtido por N multiplica√ß√µes e N-1 somas. Portanto, para uma matriz de ordem N (no caso, 1024), o n√∫mero total de opera√ß√µes de ponto flutuante necess√°rias √© aproximadamente:
2*N^3 (N = 1024)
operacoes totais = =2√ó1,073,741,824=2,147,483,648¬†FLOP

Calcular o tempo necess√°rio: Sabemos que a performance de pico √© 5 GFLOP/s (ou 5 \times 10^9 FLOP/s), ent√£o o tempo necess√°rio para realizar as opera√ß√µes de multiplica√ß√£o de matrizes pode ser calculado dividindo o n√∫mero total de FLOP pelo pico de FLOP/s:

Tempo = 2,147,483,648¬†FLOP / 5*10^9 FLOPS por s
=0.429¬†segundos


b)
O modelo roofline √© uma ferramenta gr√°fica que ajuda a visualizar como a intensidade aritm√©tica e a largura de banda de mem√≥ria afetam a performance de um algoritmo. O gr√°fico tem dois eixos:

Eixo X: Intensidade aritm√©tica (Opera√ß√µes de ponto flutuante por byte de mem√≥ria transferido).
Eixo Y: Performance de pico (medida em GFLOP/s).
No gr√°fico, a performance de pico √© representada por uma linha horizontal (o "teto" ou "roof"), que indica a m√°xima capacidade de c√°lculo da m√°quina. Essa linha mostra o m√°ximo de opera√ß√µes de ponto flutuante por segundo que a m√°quina pode executar, limitando-se pelo poder de processamento da CPU, independentemente de quantos bytes de dados a aplica√ß√£o transferiu da mem√≥ria.


c)
A intensidade aritm√©tica (em FLOP/byte) √© a rela√ß√£o entre o n√∫mero total de opera√ß√µes de ponto flutuante realizadas e a quantidade total de dados movidos entre a mem√≥ria e o processador (em bytes). A f√≥rmula √©:
itensidade aritmetica = operacoes por ponto flutuante (FLOP) / dados transferidos (bytes)

A intensidade aritm√©tica m√≠nima √© 0.25 FLOP/byte, o que significa que, para que a m√°quina n√£o seja limitada pela largura de banda, deve haver, no m√≠nimo, 0.25 opera√ß√µes de ponto flutuante para cada byte de dados transferido entre a mem√≥ria e o processador.
Conclus√£o:
A intensidade aritm√©tica m√≠nima que a m√°quina deve suportar sem ser limitada pela largura de banda de mem√≥ria √© 0.25 FLOP/byte. Se a intensidade aritm√©tica do algoritmo for menor do que esse valor, a m√°quina ser√° restrita pela largura de banda de mem√≥ria, e n√£o pela capacidade de processamento da CPU.


d)
A largura de banda de mem√≥ria √© a quantidade m√°xima de dados que podem ser transferidos entre o processador e a mem√≥ria por segundo. Se o algoritmo requer mais bytes de mem√≥ria por opera√ß√£o de ponto flutuante do que a largura de banda dispon√≠vel, o desempenho ser√° limitado pela largura de banda de mem√≥ria e n√£o pela capacidade de c√°lculo da CPU.

Em termos do modelo roofline, isso significa que, se o algoritmo for mais "pesado" em acessos √† mem√≥ria do que em opera√ß√µes de ponto flutuante, a performance ser√° restrita pela quantidade de dados que podem ser movidos para dentro e para fora da mem√≥ria, n√£o pelo poder de processamento do CPU.


e)
Com uma intensidade aritm√©tica de 0.083 FLOP/byte, a implementa√ß√£o ikj estar√° muito abaixo da linha de teto de mem√≥ria (limitada pela largura de banda). Isso significa que a performance ser√° limitada pela mem√≥ria e n√£o pela capacidade de c√°lculo da CPU, o que impede de atingir o m√°ximo de 5 GFLOP/s.


f)















